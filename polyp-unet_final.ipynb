{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:00.511167Z","iopub.status.busy":"2023-11-13T03:44:00.510257Z","iopub.status.idle":"2023-11-13T03:44:07.859970Z","shell.execute_reply":"2023-11-13T03:44:07.859145Z","shell.execute_reply.started":"2023-11-13T03:44:00.511084Z"},"trusted":true},"outputs":[],"source":["# !pip install torchinfo\n","import os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from torchvision.io import read_image\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, random_split, DataLoader, ConcatDataset\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","from torchsummary import summary\n","import torch\n","import torch.optim as optim"]},{"cell_type":"markdown","metadata":{},"source":["# Data Loader"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:08.939682Z","iopub.status.busy":"2023-11-13T03:44:08.939319Z","iopub.status.idle":"2023-11-13T03:44:08.957197Z","shell.execute_reply":"2023-11-13T03:44:08.956061Z","shell.execute_reply.started":"2023-11-13T03:44:08.939648Z"},"trusted":true},"outputs":[],"source":["class ImageData(Dataset):\n","    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n","        self.img_dir = img_dir\n","        self.label_dir = label_dir\n","        self.resize = resize\n","        self.transform = transform\n","        self.images = os.listdir(self.img_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","    def read_mask(self, mask_path):\n","        image = cv2.imread(mask_path) #995,1280,3\n","        image = cv2.resize(image, self.resize)#256,256,3\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)#^\n","\n","        lower1 = np.array([0, 100, 20])\n","        upper1 = np.array([10, 255, 255])\n","        lower2 = np.array([160,100,20])\n","        upper2 = np.array([179,255,255])\n","        lower_mask = cv2.inRange(image, lower1, upper1)\n","        upper_mask = cv2.inRange(image, lower2, upper2)\n","        \n","        red_mask = lower_mask + upper_mask\n","        red_mask[red_mask != 0] = 1\n","\n","        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n","        green_mask[green_mask != 0] = 2\n","\n","        full_mask = cv2.bitwise_or(red_mask, green_mask)\n","        full_mask = np.expand_dims(full_mask, axis=-1) \n","        full_mask = full_mask.astype(np.uint8)\n","        return full_mask\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = cv2.imread(img_path) \n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = self.read_mask(label_path) \n","        image = cv2.resize(image, self.resize)\n","        if self.transform:\n","            image = self.transform(image=image)['image'] #(-1,3,256,256)\n","        label = torch.tensor(label, dtype= torch.float32)\n","        label = label.permute(2, 0, 1)\n","\n","        return image, label\n","\n","    def show_image(self, idx):\n","        img_path = os.path.join(self.img_dir, self.images[idx])\n","        label_path = os.path.join(self.label_dir, self.images[idx])\n","        image = plt.imread(img_path)\n","        label = plt.imread(label_path)\n","        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","        axs[0].imshow(image)\n","        axs[0].set_title('Image')\n","        axs[1].imshow(label)\n","        axs[1].set_title('Label')\n","        plt.show()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:08.960029Z","iopub.status.busy":"2023-11-13T03:44:08.959729Z","iopub.status.idle":"2023-11-13T03:44:09.944069Z","shell.execute_reply":"2023-11-13T03:44:09.943153Z","shell.execute_reply.started":"2023-11-13T03:44:08.960004Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["image_path = []\n","TRAIN_DIR = '/kaggle/input/bkai-polyp/train/train'\n","# TRAIN_DIR = 'train/'\n","for root, dirs, files in os.walk(TRAIN_DIR):\n","    for file in files:\n","        path = os.path.join(root,file)\n","        image_path.append(path)\n","len(image_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:09.945395Z","iopub.status.busy":"2023-11-13T03:44:09.945138Z","iopub.status.idle":"2023-11-13T03:44:10.741069Z","shell.execute_reply":"2023-11-13T03:44:10.740169Z","shell.execute_reply.started":"2023-11-13T03:44:09.945372Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["mask_path = []\n","TRAIN_MASK_DIR = '/kaggle/input/bkai-polyp/train_gt/train_gt'\n","# TRAIN_MASK_DIR = 'train_gt/'\n","for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n","    for file in files:\n","        path = os.path.join(root,file)\n","        mask_path.append(path)\n","len(mask_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2000\n"]},{"name":"stderr","output_type":"stream","text":["/Users/quocdetran/miniforge3/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n","  warnings.warn(\n"]}],"source":["batch_size = 8\n","train_transform = A.Compose([\n","    A.VerticalFlip(p=0.5),\n","    A.HorizontalFlip(p=0.5),\n","    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n","    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n","    A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n","    A.Cutout(p=0.2, max_h_size=35, max_w_size=35, fill_value=255),\n","    A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n","    A.RandomShadow(p=0.1),\n","    A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    A.Rotate(limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n","    ToTensorV2()\n","])\n","\n","val_transform = A.Compose([\n","    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(),\n","])\n","\n","train_dataset_not_aug = ImageData(img_dir= TRAIN_DIR,\n","                             label_dir= TRAIN_MASK_DIR,\n","                             resize= (224,224),\n","                             transform = val_transform)\n","\n","train_dataset_aug = ImageData(img_dir= TRAIN_DIR,\n","                             label_dir= TRAIN_MASK_DIR,\n","                             resize= (224,224),\n","                             transform = train_transform)\n","train_dataset = ConcatDataset([train_dataset_not_aug, train_dataset_aug])\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","print(len(train_dataset))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([8, 3, 224, 224])\n","torch.Size([8, 1, 224, 224])\n"]}],"source":["for i,(data,label) in enumerate(train_loader):\n","    print(data.shape)\n","    print(label.shape)\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:11.316359Z","iopub.status.busy":"2023-11-13T03:44:11.316025Z","iopub.status.idle":"2023-11-13T03:44:11.328537Z","shell.execute_reply":"2023-11-13T03:44:11.327623Z","shell.execute_reply.started":"2023-11-13T03:44:11.316328Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision.models import resnet50, ResNet50_Weights\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        return x\n","\n","\n","class BottleNeck(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.bottleneck = nn.Sequential(\n","            ConvBlock(in_channels, out_channels),\n","            ConvBlock(out_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.bottleneck(x)\n","\n","\n","class UpsampleBlock(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n","                 ):\n","        super().__init__()\n","\n","        if up_conv_in_channels is None:\n","            up_conv_in_channels = in_channels\n","        if up_conv_out_channels is None:\n","            up_conv_out_channels = out_channels\n","        self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n","        \n","        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n","        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n","\n","    def forward(self, up_x, down_x):\n","        x = self.upsample(up_x) #(-1,1024,-,-)\n","        x = torch.cat([x, down_x], 1) #(-1,2048,-,-) # channels nhân đôi lên\n","        x = self.conv_block_1(x)#(-1,1024,-,-)\n","        x = self.conv_block_2(x)\n","        return x\n","\n","\n","class ResnetUnet(nn.Module):\n","    DEPTH = 6\n","\n","    def __init__(self, n_classes=2):\n","        super().__init__()\n","        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n","\n","        enc_blocks = []\n","\n","        self.input_block= nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n","            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.input_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","        \n","        for enc in list(resnet.children()):\n","            if isinstance(enc, nn.Sequential):\n","                enc_blocks.append(enc)\n","        self.enc_blocks = nn.ModuleList(enc_blocks)\n","        \n","        self.bottleneck = BottleNeck(2048, 2048)\n","\n","        dec_blocks = []\n","        dec_blocks.append(UpsampleBlock(2048, 1024))\n","        dec_blocks.append(UpsampleBlock(1024, 512))\n","        dec_blocks.append(UpsampleBlock(512, 256))\n","        dec_blocks.append(UpsampleBlock(in_channels=128 + 64, out_channels=128, up_conv_in_channels=256, up_conv_out_channels=128))\n","        dec_blocks.append(UpsampleBlock(in_channels=64 + 3, out_channels=64, up_conv_in_channels=128, up_conv_out_channels=64))\n","        self.dec_blocks = nn.ModuleList(dec_blocks)\n","\n","        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n","\n","    def forward(self, x):\n","        pre_pools = dict() # to save skip-connection\n","        pre_pools[\"layer_0\"] = x\n","        x = self.input_block(x) # (-1,64,112,112)\n","        pre_pools[\"layer_1\"] = x\n","        x = self.input_pool(x) #-1,64,56,56\n","\n","        for i, block in enumerate(self.enc_blocks, 2):\n","            x = block(x)\n","            if i == (ResnetUnet.DEPTH - 1):\n","                continue\n","            pre_pools[f\"layer_{i}\"] = x # save the skip-connection\n","\n","        x = self.bottleneck(x) #(-1,2048,224,224)\n","\n","        for i, block in enumerate(self.dec_blocks, 1):\n","            key = f\"layer_{ResnetUnet.DEPTH - 1 - i}\"\n","            x = block(x, pre_pools[key]) # decode with x and saved skip-connection\n","        x = self.out(x)\n","        del pre_pools\n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","def mask2rgb(mask):\n","    color_dict = {0: torch.tensor([0, 0, 0]),\n","                  1: torch.tensor([1, 0, 0]),\n","                  2: torch.tensor([0, 1, 0])}\n","    output = torch.zeros((mask.shape[0], mask.shape[1], mask.shape[2], 3)).long()\n","    for i in range(mask.shape[0]):\n","        for k in color_dict.keys():\n","            output[i][mask[i].long() == k] = color_dict[k]\n","    return output.to(mask.device)\n","\n","\n","@torch.no_grad()\n","def dice_score(\n","    inputs: torch.Tensor,\n","    targets: torch.Tensor\n",") -> torch.Tensor:\n","    # compute softmax over the classes axis\n","    input_one_hot = mask2rgb(inputs.argmax(dim=1))\n","\n","    # create the labels one hot tensor\n","    target_one_hot = mask2rgb(targets)\n","\n","    # compute the actual dice score\n","    dims = (2, 3)\n","    intersection = torch.sum(input_one_hot * target_one_hot, dims)\n","    cardinality = torch.sum(input_one_hot + target_one_hot, dims)\n","\n","    dice_score = (2. * intersection + 1e-6) / (cardinality + 1e-6)\n","    return dice_score.mean()\n","\n","\n","class DiceLoss(nn.Module):\n","    def __init__(self, weights=torch.Tensor([[0.4, 0.55, 0.05]])) -> None:\n","        super(DiceLoss, self).__init__()\n","        self.eps: float = 1e-6\n","        self.weights: torch.Tensor = weights\n","\n","    def forward(\n","            self,\n","            inputs: torch.Tensor,\n","            targets: torch.Tensor) -> torch.Tensor:\n","        # compute softmax over the classes axis\n","        input_soft = F.softmax(inputs, dim=1)\n","\n","        # create the labels one hot tensor\n","        target_one_hot = mask2rgb(targets)\n","\n","        # compute the actual dice score\n","        dims = (2, 3)\n","        intersection = torch.sum(input_soft * target_one_hot, dims)\n","        cardinality = torch.sum(input_soft + target_one_hot, dims)\n","\n","        dice_score = 2. * intersection / (cardinality + self.eps)\n","\n","        dice_score = torch.sum(\n","            dice_score * self.weights.to(dice_score.device),\n","            dim=1\n","        )\n","        return torch.mean(1. - dice_score)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:11.329830Z","iopub.status.busy":"2023-11-13T03:44:11.329554Z","iopub.status.idle":"2023-11-13T03:44:11.338734Z","shell.execute_reply":"2023-11-13T03:44:11.337757Z","shell.execute_reply.started":"2023-11-13T03:44:11.329799Z"},"trusted":true},"outputs":[],"source":["color_dict= {0: (0, 0, 0),\n","             1: (255, 0, 0),\n","             2: (0, 255, 0)}\n","def mask_to_rgb(mask, color_dict):\n","    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n","    for k in color_dict.keys():\n","        output[mask==k] = color_dict[k]\n","\n","    return np.uint8(output)    "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:44:11.340037Z","iopub.status.busy":"2023-11-13T03:44:11.339761Z","iopub.status.idle":"2023-11-13T03:44:11.634726Z","shell.execute_reply":"2023-11-13T03:44:11.633693Z","shell.execute_reply.started":"2023-11-13T03:44:11.340013Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Resnet152Unet(\n","  (input_block): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (input_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (enc_blocks): ModuleList(\n","    (0): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (23): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (24): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (25): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (26): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (27): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (28): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (29): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (30): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (31): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (32): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (33): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (34): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (35): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (bottleneck): BottleNeck(\n","    (bottleneck): Sequential(\n","      (0): ConvBlock(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (1): ConvBlock(\n","        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","  )\n","  (dec_blocks): ModuleList(\n","    (0): UpsampleBlock(\n","      (upsample): ConvTranspose2d(2048, 1024, kernel_size=(2, 2), stride=(2, 2))\n","      (conv_block_1): ConvBlock(\n","        (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (conv_block_2): ConvBlock(\n","        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (1): UpsampleBlock(\n","      (upsample): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n","      (conv_block_1): ConvBlock(\n","        (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (conv_block_2): ConvBlock(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (2): UpsampleBlock(\n","      (upsample): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (conv_block_1): ConvBlock(\n","        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (conv_block_2): ConvBlock(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (3): UpsampleBlock(\n","      (upsample): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n","      (conv_block_1): ConvBlock(\n","        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (conv_block_2): ConvBlock(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","    (4): UpsampleBlock(\n","      (upsample): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","      (conv_block_1): ConvBlock(\n","        (conv): Conv2d(67, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","      (conv_block_2): ConvBlock(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","      )\n","    )\n","  )\n","  (out): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","model = ResnetUnet(n_classes=3)\n","model.to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-80          [-1, 128, 28, 28]             256\n","             ReLU-81          [-1, 128, 28, 28]               0\n","           Conv2d-82          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-83          [-1, 128, 28, 28]             256\n","             ReLU-84          [-1, 128, 28, 28]               0\n","           Conv2d-85          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n","             ReLU-87          [-1, 512, 28, 28]               0\n","       Bottleneck-88          [-1, 512, 28, 28]               0\n","           Conv2d-89          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-90          [-1, 128, 28, 28]             256\n","             ReLU-91          [-1, 128, 28, 28]               0\n","           Conv2d-92          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-93          [-1, 128, 28, 28]             256\n","             ReLU-94          [-1, 128, 28, 28]               0\n","           Conv2d-95          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n","             ReLU-97          [-1, 512, 28, 28]               0\n","       Bottleneck-98          [-1, 512, 28, 28]               0\n","           Conv2d-99          [-1, 128, 28, 28]          65,536\n","     BatchNorm2d-100          [-1, 128, 28, 28]             256\n","            ReLU-101          [-1, 128, 28, 28]               0\n","          Conv2d-102          [-1, 128, 28, 28]         147,456\n","     BatchNorm2d-103          [-1, 128, 28, 28]             256\n","            ReLU-104          [-1, 128, 28, 28]               0\n","          Conv2d-105          [-1, 512, 28, 28]          65,536\n","     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n","            ReLU-107          [-1, 512, 28, 28]               0\n","      Bottleneck-108          [-1, 512, 28, 28]               0\n","          Conv2d-109          [-1, 128, 28, 28]          65,536\n","     BatchNorm2d-110          [-1, 128, 28, 28]             256\n","            ReLU-111          [-1, 128, 28, 28]               0\n","          Conv2d-112          [-1, 128, 28, 28]         147,456\n","     BatchNorm2d-113          [-1, 128, 28, 28]             256\n","            ReLU-114          [-1, 128, 28, 28]               0\n","          Conv2d-115          [-1, 512, 28, 28]          65,536\n","     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n","            ReLU-117          [-1, 512, 28, 28]               0\n","      Bottleneck-118          [-1, 512, 28, 28]               0\n","          Conv2d-119          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-120          [-1, 256, 28, 28]             512\n","            ReLU-121          [-1, 256, 28, 28]               0\n","          Conv2d-122          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-123          [-1, 256, 14, 14]             512\n","            ReLU-124          [-1, 256, 14, 14]               0\n","          Conv2d-125         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n","          Conv2d-127         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-312          [-1, 256, 14, 14]             512\n","            ReLU-313          [-1, 256, 14, 14]               0\n","          Conv2d-314          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-315          [-1, 256, 14, 14]             512\n","            ReLU-316          [-1, 256, 14, 14]               0\n","          Conv2d-317         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n","            ReLU-319         [-1, 1024, 14, 14]               0\n","      Bottleneck-320         [-1, 1024, 14, 14]               0\n","          Conv2d-321          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-322          [-1, 256, 14, 14]             512\n","            ReLU-323          [-1, 256, 14, 14]               0\n","          Conv2d-324          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-325          [-1, 256, 14, 14]             512\n","            ReLU-326          [-1, 256, 14, 14]               0\n","          Conv2d-327         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n","            ReLU-329         [-1, 1024, 14, 14]               0\n","      Bottleneck-330         [-1, 1024, 14, 14]               0\n","          Conv2d-331          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-332          [-1, 256, 14, 14]             512\n","            ReLU-333          [-1, 256, 14, 14]               0\n","          Conv2d-334          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-335          [-1, 256, 14, 14]             512\n","            ReLU-336          [-1, 256, 14, 14]               0\n","          Conv2d-337         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n","            ReLU-339         [-1, 1024, 14, 14]               0\n","      Bottleneck-340         [-1, 1024, 14, 14]               0\n","          Conv2d-341          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-342          [-1, 256, 14, 14]             512\n","            ReLU-343          [-1, 256, 14, 14]               0\n","          Conv2d-344          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-345          [-1, 256, 14, 14]             512\n","            ReLU-346          [-1, 256, 14, 14]               0\n","          Conv2d-347         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n","            ReLU-349         [-1, 1024, 14, 14]               0\n","      Bottleneck-350         [-1, 1024, 14, 14]               0\n","          Conv2d-351          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-352          [-1, 256, 14, 14]             512\n","            ReLU-353          [-1, 256, 14, 14]               0\n","          Conv2d-354          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-355          [-1, 256, 14, 14]             512\n","            ReLU-356          [-1, 256, 14, 14]               0\n","          Conv2d-357         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n","            ReLU-359         [-1, 1024, 14, 14]               0\n","      Bottleneck-360         [-1, 1024, 14, 14]               0\n","          Conv2d-361          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-362          [-1, 256, 14, 14]             512\n","            ReLU-363          [-1, 256, 14, 14]               0\n","          Conv2d-364          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-365          [-1, 256, 14, 14]             512\n","            ReLU-366          [-1, 256, 14, 14]               0\n","          Conv2d-367         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n","            ReLU-369         [-1, 1024, 14, 14]               0\n","      Bottleneck-370         [-1, 1024, 14, 14]               0\n","          Conv2d-371          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-372          [-1, 256, 14, 14]             512\n","            ReLU-373          [-1, 256, 14, 14]               0\n","          Conv2d-374          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-375          [-1, 256, 14, 14]             512\n","            ReLU-376          [-1, 256, 14, 14]               0\n","          Conv2d-377         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n","            ReLU-379         [-1, 1024, 14, 14]               0\n","      Bottleneck-380         [-1, 1024, 14, 14]               0\n","          Conv2d-381          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-382          [-1, 256, 14, 14]             512\n","            ReLU-383          [-1, 256, 14, 14]               0\n","          Conv2d-384          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-385          [-1, 256, 14, 14]             512\n","            ReLU-386          [-1, 256, 14, 14]               0\n","          Conv2d-387         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n","            ReLU-389         [-1, 1024, 14, 14]               0\n","      Bottleneck-390         [-1, 1024, 14, 14]               0\n","          Conv2d-391          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-392          [-1, 256, 14, 14]             512\n","            ReLU-393          [-1, 256, 14, 14]               0\n","          Conv2d-394          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-395          [-1, 256, 14, 14]             512\n","            ReLU-396          [-1, 256, 14, 14]               0\n","          Conv2d-397         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n","            ReLU-399         [-1, 1024, 14, 14]               0\n","      Bottleneck-400         [-1, 1024, 14, 14]               0\n","          Conv2d-401          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-402          [-1, 256, 14, 14]             512\n","            ReLU-403          [-1, 256, 14, 14]               0\n","          Conv2d-404          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-405          [-1, 256, 14, 14]             512\n","            ReLU-406          [-1, 256, 14, 14]               0\n","          Conv2d-407         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n","            ReLU-409         [-1, 1024, 14, 14]               0\n","      Bottleneck-410         [-1, 1024, 14, 14]               0\n","          Conv2d-411          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-412          [-1, 256, 14, 14]             512\n","            ReLU-413          [-1, 256, 14, 14]               0\n","          Conv2d-414          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-415          [-1, 256, 14, 14]             512\n","            ReLU-416          [-1, 256, 14, 14]               0\n","          Conv2d-417         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n","            ReLU-419         [-1, 1024, 14, 14]               0\n","      Bottleneck-420         [-1, 1024, 14, 14]               0\n","          Conv2d-421          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-422          [-1, 256, 14, 14]             512\n","            ReLU-423          [-1, 256, 14, 14]               0\n","          Conv2d-424          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-425          [-1, 256, 14, 14]             512\n","            ReLU-426          [-1, 256, 14, 14]               0\n","          Conv2d-427         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n","            ReLU-429         [-1, 1024, 14, 14]               0\n","      Bottleneck-430         [-1, 1024, 14, 14]               0\n","          Conv2d-431          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-432          [-1, 256, 14, 14]             512\n","            ReLU-433          [-1, 256, 14, 14]               0\n","          Conv2d-434          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-435          [-1, 256, 14, 14]             512\n","            ReLU-436          [-1, 256, 14, 14]               0\n","          Conv2d-437         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n","            ReLU-439         [-1, 1024, 14, 14]               0\n","      Bottleneck-440         [-1, 1024, 14, 14]               0\n","          Conv2d-441          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-442          [-1, 256, 14, 14]             512\n","            ReLU-443          [-1, 256, 14, 14]               0\n","          Conv2d-444          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-445          [-1, 256, 14, 14]             512\n","            ReLU-446          [-1, 256, 14, 14]               0\n","          Conv2d-447         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n","            ReLU-449         [-1, 1024, 14, 14]               0\n","      Bottleneck-450         [-1, 1024, 14, 14]               0\n","          Conv2d-451          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-452          [-1, 256, 14, 14]             512\n","            ReLU-453          [-1, 256, 14, 14]               0\n","          Conv2d-454          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-455          [-1, 256, 14, 14]             512\n","            ReLU-456          [-1, 256, 14, 14]               0\n","          Conv2d-457         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n","            ReLU-459         [-1, 1024, 14, 14]               0\n","      Bottleneck-460         [-1, 1024, 14, 14]               0\n","          Conv2d-461          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-462          [-1, 256, 14, 14]             512\n","            ReLU-463          [-1, 256, 14, 14]               0\n","          Conv2d-464          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-465          [-1, 256, 14, 14]             512\n","            ReLU-466          [-1, 256, 14, 14]               0\n","          Conv2d-467         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n","            ReLU-469         [-1, 1024, 14, 14]               0\n","      Bottleneck-470         [-1, 1024, 14, 14]               0\n","          Conv2d-471          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-472          [-1, 256, 14, 14]             512\n","            ReLU-473          [-1, 256, 14, 14]               0\n","          Conv2d-474          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-475          [-1, 256, 14, 14]             512\n","            ReLU-476          [-1, 256, 14, 14]               0\n","          Conv2d-477         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n","            ReLU-479         [-1, 1024, 14, 14]               0\n","      Bottleneck-480         [-1, 1024, 14, 14]               0\n","          Conv2d-481          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n","            ReLU-483          [-1, 512, 14, 14]               0\n","          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n","            ReLU-486            [-1, 512, 7, 7]               0\n","          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n","          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n","            ReLU-491           [-1, 2048, 7, 7]               0\n","      Bottleneck-492           [-1, 2048, 7, 7]               0\n","          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n","            ReLU-495            [-1, 512, 7, 7]               0\n","          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n","            ReLU-498            [-1, 512, 7, 7]               0\n","          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n","            ReLU-501           [-1, 2048, 7, 7]               0\n","      Bottleneck-502           [-1, 2048, 7, 7]               0\n","          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n","            ReLU-505            [-1, 512, 7, 7]               0\n","          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n","            ReLU-508            [-1, 512, 7, 7]               0\n","          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n","            ReLU-511           [-1, 2048, 7, 7]               0\n","      Bottleneck-512           [-1, 2048, 7, 7]               0\n","          Conv2d-513           [-1, 2048, 7, 7]      37,750,784\n","     BatchNorm2d-514           [-1, 2048, 7, 7]           4,096\n","            ReLU-515           [-1, 2048, 7, 7]               0\n","       ConvBlock-516           [-1, 2048, 7, 7]               0\n","          Conv2d-517           [-1, 2048, 7, 7]      37,750,784\n","     BatchNorm2d-518           [-1, 2048, 7, 7]           4,096\n","            ReLU-519           [-1, 2048, 7, 7]               0\n","       ConvBlock-520           [-1, 2048, 7, 7]               0\n","      BottleNeck-521           [-1, 2048, 7, 7]               0\n"," ConvTranspose2d-522         [-1, 1024, 14, 14]       8,389,632\n","          Conv2d-523         [-1, 1024, 14, 14]      18,875,392\n","     BatchNorm2d-524         [-1, 1024, 14, 14]           2,048\n","            ReLU-525         [-1, 1024, 14, 14]               0\n","       ConvBlock-526         [-1, 1024, 14, 14]               0\n","          Conv2d-527         [-1, 1024, 14, 14]       9,438,208\n","     BatchNorm2d-528         [-1, 1024, 14, 14]           2,048\n","            ReLU-529         [-1, 1024, 14, 14]               0\n","       ConvBlock-530         [-1, 1024, 14, 14]               0\n","   UpsampleBlock-531         [-1, 1024, 14, 14]               0\n"," ConvTranspose2d-532          [-1, 512, 28, 28]       2,097,664\n","          Conv2d-533          [-1, 512, 28, 28]       4,719,104\n","     BatchNorm2d-534          [-1, 512, 28, 28]           1,024\n","            ReLU-535          [-1, 512, 28, 28]               0\n","       ConvBlock-536          [-1, 512, 28, 28]               0\n","          Conv2d-537          [-1, 512, 28, 28]       2,359,808\n","     BatchNorm2d-538          [-1, 512, 28, 28]           1,024\n","            ReLU-539          [-1, 512, 28, 28]               0\n","       ConvBlock-540          [-1, 512, 28, 28]               0\n","   UpsampleBlock-541          [-1, 512, 28, 28]               0\n"," ConvTranspose2d-542          [-1, 256, 56, 56]         524,544\n","          Conv2d-543          [-1, 256, 56, 56]       1,179,904\n","     BatchNorm2d-544          [-1, 256, 56, 56]             512\n","            ReLU-545          [-1, 256, 56, 56]               0\n","       ConvBlock-546          [-1, 256, 56, 56]               0\n","          Conv2d-547          [-1, 256, 56, 56]         590,080\n","     BatchNorm2d-548          [-1, 256, 56, 56]             512\n","            ReLU-549          [-1, 256, 56, 56]               0\n","       ConvBlock-550          [-1, 256, 56, 56]               0\n","   UpsampleBlock-551          [-1, 256, 56, 56]               0\n"," ConvTranspose2d-552        [-1, 128, 112, 112]         131,200\n","          Conv2d-553        [-1, 128, 112, 112]         221,312\n","     BatchNorm2d-554        [-1, 128, 112, 112]             256\n","            ReLU-555        [-1, 128, 112, 112]               0\n","       ConvBlock-556        [-1, 128, 112, 112]               0\n","          Conv2d-557        [-1, 128, 112, 112]         147,584\n","     BatchNorm2d-558        [-1, 128, 112, 112]             256\n","            ReLU-559        [-1, 128, 112, 112]               0\n","       ConvBlock-560        [-1, 128, 112, 112]               0\n","   UpsampleBlock-561        [-1, 128, 112, 112]               0\n"," ConvTranspose2d-562         [-1, 64, 224, 224]          32,832\n","          Conv2d-563         [-1, 64, 224, 224]          38,656\n","     BatchNorm2d-564         [-1, 64, 224, 224]             128\n","            ReLU-565         [-1, 64, 224, 224]               0\n","       ConvBlock-566         [-1, 64, 224, 224]               0\n","          Conv2d-567         [-1, 64, 224, 224]          36,928\n","     BatchNorm2d-568         [-1, 64, 224, 224]             128\n","            ReLU-569         [-1, 64, 224, 224]               0\n","       ConvBlock-570         [-1, 64, 224, 224]               0\n","   UpsampleBlock-571         [-1, 64, 224, 224]               0\n","          Conv2d-572          [-1, 3, 224, 224]             195\n","================================================================\n","Total params: 182,444,547\n","Trainable params: 182,444,547\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 1089.29\n","Params size (MB): 695.97\n","Estimated Total Size (MB): 1785.84\n","----------------------------------------------------------------\n"]}],"source":["import torchsummary\n","torchsummary.summary(model,(3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["learning_rate = 0.001\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:45:47.409321Z","iopub.status.busy":"2023-11-13T03:45:47.408931Z","iopub.status.idle":"2023-11-13T03:46:04.006769Z","shell.execute_reply":"2023-11-13T03:46:04.005564Z","shell.execute_reply.started":"2023-11-13T03:45:47.409289Z"},"trusted":true},"outputs":[],"source":["import wandb"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["!wandb login --relogin cb5c67c48112693f46651a427df0d125433e1027"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:46:09.870715Z","iopub.status.busy":"2023-11-13T03:46:09.869975Z","iopub.status.idle":"2023-11-13T03:46:43.084739Z","shell.execute_reply":"2023-11-13T03:46:43.083826Z","shell.execute_reply.started":"2023-11-13T03:46:09.870678Z"},"trusted":true},"outputs":[],"source":["wandb.init(\n","    project = 'Segmentation-UNET',\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-13T03:46:43.087863Z","iopub.status.busy":"2023-11-13T03:46:43.087131Z","iopub.status.idle":"2023-11-13T03:48:52.619022Z","shell.execute_reply":"2023-11-13T03:48:52.616949Z","shell.execute_reply.started":"2023-11-13T03:46:43.087833Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["loss :  tensor(0.9644, grad_fn=<NllLoss2DBackward0>)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/quocdetran/Downloads/DL-hw3/polyp-unet_final.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quocdetran/Downloads/DL-hw3/polyp-unet_final.ipynb#X21sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m acc \u001b[39m=\u001b[39m (outputs\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quocdetran/Downloads/DL-hw3/polyp-unet_final.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mloss : \u001b[39m\u001b[39m\"\u001b[39m,loss)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/quocdetran/Downloads/DL-hw3/polyp-unet_final.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quocdetran/Downloads/DL-hw3/polyp-unet_final.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/quocdetran/Downloads/DL-hw3/polyp-unet_final.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n","File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n","File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 100\n","trainsize = 224\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","train_loss_array = []\n","best_loss = 999\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    total_acc = 0\n","    # i = 0\n","    for images, labels in train_loader:\n","        # i+=1\n","        # print(i)\n","        images = images.to(device) #(-1,3,224,224)\n","        labels = labels.to(device) #(-1,1,224,2224)\n","        # Forward pass\n","        labels = labels.squeeze(dim=1).long()#(-1,224,24)\n","\n","        outputs = model(images) #(-1,3,224,224)\n","\n","        loss = criterion(outputs, labels)\n","        acc = (outputs.argmax(dim=1) == labels).float().mean()\n","\n","        print(\"loss : \",loss)\n","        \n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        total_loss += loss.item()  \n","        total_acc+= acc\n","\n","    epoch_loss = total_loss / len(train_loader)\n","    epoch_acc = total_acc / len(train_loader)\n","    train_loss_array.append(epoch_loss)\n","    wandb.log({'Loss': epoch_loss , 'Acc: ':acc})\n","    \n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.10f}\")\n","    \n","    if epoch_loss < best_loss:\n","        best_loss = epoch_loss\n","        checkpoint = { \n","            'epoch': epoch,\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'loss': epoch_loss\n","        }\n","        save_path = '/kaggle/working/saved_model_submission.pth'\n","        torch.save(checkpoint, save_path)\n","        print('Save model')\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:48:52.620318Z","iopub.status.idle":"2023-11-13T03:48:52.620823Z","shell.execute_reply":"2023-11-13T03:48:52.620590Z","shell.execute_reply.started":"2023-11-13T03:48:52.620563Z"},"trusted":true},"outputs":[],"source":["checkpoint = torch.load('/kaggle/working/saved_model_submission.pth')\n","model.load_state_dict(checkpoint['model'])\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) \n","optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","model.to(device)\n","for state in optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.to(device)\n","loss_value = checkpoint['loss']\n","\n","print(f\"The loss from the checkpoint is: {loss_value:.10f}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:48:52.622145Z","iopub.status.idle":"2023-11-13T03:48:52.622632Z","shell.execute_reply":"2023-11-13T03:48:52.622408Z","shell.execute_reply.started":"2023-11-13T03:48:52.622384Z"},"trusted":true},"outputs":[],"source":["!mkdir test_pred\n","!mkdir test_overlappred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:48:52.624042Z","iopub.status.idle":"2023-11-13T03:48:52.624554Z","shell.execute_reply":"2023-11-13T03:48:52.624328Z","shell.execute_reply.started":"2023-11-13T03:48:52.624301Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n","    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n","    ori_img = cv2.imread(img_path)\n","    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n","    ori_w = ori_img.shape[0]\n","    ori_h = ori_img.shape[1]\n","    img = cv2.resize(ori_img, (trainsize, trainsize))\n","    transformed = val_transform(image=img)\n","    input_img = transformed[\"image\"]\n","    input_img = input_img.unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n","    mask = cv2.resize(output_mask, (ori_h, ori_w))\n","    mask = np.argmax(mask, axis=2)\n","    new_rgb_mask = np.zeros((*mask.shape, 3)).astype(np.uint8)\n","    mask_rgb = mask_to_rgb(mask, color_dict)\n","    mask_rgb_true = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2RGB)\n","    overlap = 0.7*ori_img+0.3*mask_rgb_true\n","    overlap = overlap.astype('uint8')\n","    overlap = cv2.cvtColor(overlap, cv2.COLOR_RGB2BGR)\n","    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n","    cv2.imwrite(\"test_pred/{}\".format(i), mask_rgb)\n","    cv2.imwrite(\"test_overlappred/{}\".format(i), overlap)\n","    print(\"processed \", img_path)\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:48:52.626134Z","iopub.status.idle":"2023-11-13T03:48:52.626629Z","shell.execute_reply":"2023-11-13T03:48:52.626393Z","shell.execute_reply.started":"2023-11-13T03:48:52.626368Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","\n","def rle_to_string(runs):\n","    return ' '.join(str(x) for x in runs)\n","\n","def rle_encode_one_mask(mask):\n","    pixels = mask.flatten()\n","    pixels[pixels > 225] = 255\n","    pixels[pixels <= 225] = 0\n","    use_padding = False\n","    if pixels[0] or pixels[-1]:\n","        use_padding = True\n","        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n","        pixel_padded[1:-1] = pixels\n","        pixels = pixel_padded\n","    \n","    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n","    if use_padding:\n","        rle = rle - 1\n","    rle[1::2] = rle[1::2] - rle[:-1:2]\n","    return rle_to_string(rle)\n","\n","def rle2mask(mask_rle, shape=(3,3)):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (width,height) of array to return \n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape).T\n","\n","def mask2string(dir):\n","    ## mask --> string\n","    strings = []\n","    ids = []\n","    ws, hs = [[] for i in range(2)]\n","    for image_id in os.listdir(dir):\n","        id = image_id.split('.')[0]\n","        path = os.path.join(dir, image_id)\n","        print(path)\n","        img = cv2.imread(path)[:,:,::-1]\n","        h, w = img.shape[0], img.shape[1]\n","        for channel in range(2):\n","            ws.append(w)\n","            hs.append(h)\n","            ids.append(f'{id}_{channel}')\n","            string = rle_encode_one_mask(img[:,:,channel])\n","            strings.append(string)\n","    r = {\n","        'ids': ids,\n","        'strings': strings,\n","    }\n","    return r\n","\n","\n","MASK_DIR_PATH = 'test_predict/' # change this to the path to your output mask folder\n","dir = MASK_DIR_PATH\n","res = mask2string(dir)\n","df = pd.DataFrame(columns=['Id', 'Expected'])\n","df['Id'] = res['ids']\n","df['Expected'] = res['strings']\n","\n","df.to_csv(r'output.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-13T03:48:52.629434Z","iopub.status.idle":"2023-11-13T03:48:52.629879Z","shell.execute_reply":"2023-11-13T03:48:52.629676Z","shell.execute_reply.started":"2023-11-13T03:48:52.629655Z"},"trusted":true},"outputs":[],"source":["%%sh\n","killall5 -9"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3994584,"sourceId":6954859,"sourceType":"datasetVersion"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
